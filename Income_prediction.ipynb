{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a46348b-655d-4ef6-b280-41f79bd1d9fb",
   "metadata": {},
   "source": [
    "Zadanie polega na przewidzeniu, czy roczny dochód danej osoby przekracza 50 000 USD (zmienna powyżej lub poniżej progu „$50K/yr”) na podstawie danych demograficznych i społeczno-zawodowych pochodzących z bazy spisu ludności."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed16ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1426291b-d1f9-49a5-ae8e-6d0f4c4f2658",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b54d80-1815-4dcc-a5bb-7fcd6a5bee59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets \n",
    "  \n",
    "# metadata \n",
    "#print(adult.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(adult.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10450cfb-21e4-499d-a239-7a5c716606fe",
   "metadata": {},
   "source": [
    "Liczba rekordów: 48842.\n",
    "\n",
    "Liczba atrybutów: 14 cech wejściowych (predyktorów) oraz 1 zmienna celu.\n",
    "\n",
    "Charakterystyka danych: Zbiór zawiera zarówno zmienne numeryczne (całkowitoliczbowe), jak i kategoryczne (tekstowe).\n",
    "\n",
    "Zmienna celu (income): Zmienna binarna przyjmująca wartości >50K lub<=50K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee2789-c96f-4222-8580-28b8cc44f57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pierwsze 5 wierszy cech\n",
    "print(X.head())\n",
    "\n",
    "# Informacje o typach danych i liczbie niepustych wartości\n",
    "print(X.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba61bd2-d1ce-4957-a104-6a7c54590e4f",
   "metadata": {},
   "source": [
    "1. **age:** Wiek badanej osoby (liczba ciągła)\n",
    "2. **workclass:** Forma zatrudnienia (np. Private, Self-emp-not-inc, Federal-gov)\n",
    "3. **fnlwgt:** Waga demograficzna, liczba osób reprezentowanych przez rekord. (final weight)\n",
    "4. **education:** Najwyższy stopień edukacji (np. Bachelors, Masters, HS-grad)\n",
    "5. **education-num:** Poziom edukacji ujęty numerycznie (liczba ciągła)\n",
    "6. **marital-status:** Stan cywilny (np. Married-civ-spouse, Never-married)\n",
    "7. **occupation:** Wykonywany zawód (np. Tech-support, Exec-managerial)\n",
    "8. **relationship:** Rola w rodzinie (np. Husband, Not-in-family)\n",
    "9. **race:** Rasa (np. White, Black, Asian-Pac-Islander)\n",
    "10. **sex:** Płeć (Male, Female)\n",
    "11. **capital-gain:** Zyski kapitałowe (liczba ciągła)\n",
    "12. **capital-loss:** Straty kapitałowe (liczba ciągła)\n",
    "13. **hours-per-week:** Liczba przepracowanych godzin w tygodniu (liczba ciągła)\n",
    "14. **native-country:** Kraj pochodzenia (np. United-States, Mexico, Germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9aff67-6c77-4f63-84d0-b41e192d4237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unikalne wartości w kolumnie celu\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a85f481-6b95-4330-b343-78a7672b49e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sprawdzenie czy w danych występują znaki zapytania\n",
    "print((X == '?').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d6fedc-6437-4dad-aba3-b0966da99133",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Kopia danych, aby nie modyfikować oryginału z repozytorium\n",
    "df_X = X.copy()\n",
    "df_y = y.copy()\n",
    "\n",
    "# Stan przed zmianami\n",
    "print(f\"Liczba wierszy przed czyszczeniem: {len(df_X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ed24cd-77fd-469a-b7c9-257201a3b3a9",
   "metadata": {},
   "source": [
    "Najpierw oczyszczono zmienną income, bo w danych były kropki na końcu niektórych kategorii. Usunięto je i zamieniono tekst na wartości binarne, gdzie zero oznacza zarobki do 50 tysięcy, a jedynka powyżej."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9747e805-dcab-4954-8231-6e317c48682e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Czyszczenie zmiennej celu\n",
    "# Usuwamy kropki, które pojawiają się w niektórych rekordach\n",
    "df_y['income'] = df_y['income'].astype(str).str.replace('.', '', regex=False)\n",
    "\n",
    "# Mapowanie na wartości binarne (0 i 1)\n",
    "# <=50K -> 0\n",
    "# >50K -> 1\n",
    "df_y['income'] = df_y['income'].map({'<=50K': 0, '>50K': 1})\n",
    "\n",
    "print(\"Rozkład klas po czyszczeniu:\")\n",
    "print(df_y['income'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46f7911-171d-4264-a0f7-8eb80215414b",
   "metadata": {},
   "source": [
    "W zbiorze Adult braki danych są ukryte pod znakami zapytania, co jest problematyczne dla algorytmów. Zamieniono wszystkie te znaki na format zrozumiały dla Pythona (NaN), a potem użyliśmy strategii SimpleImputer, wstawiając w puste miejsca najczęściej występujące wartości z danej kolumny."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be468cc5-e6c9-4a81-8417-44d6c1e2ea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zamiana '?' na np.nan\n",
    "df_X.replace('?', np.nan, inplace=True)\n",
    "\n",
    "# Sprawdzenie ile mamy teraz prawdziwych braków\n",
    "print(\"\\nLiczba braków danych w kolumnach:\")\n",
    "print(df_X.isnull().sum())\n",
    "\n",
    "# Imputacja braków danych najczęstszą wartością\n",
    "# Tworzymy imputer\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Uzupełniamy dane\n",
    "df_X_imputed = pd.DataFrame(imputer.fit_transform(df_X), columns=df_X.columns)\n",
    "\n",
    "# Przywracamy poprawne typy danych\n",
    "df_X_imputed = df_X_imputed.infer_objects()\n",
    "\n",
    "# Upewnienie że kolumny numeryczne są numeryczne\n",
    "num_cols = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "for col in num_cols:\n",
    "    df_X_imputed[col] = df_X_imputed[col].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08fbb50-3099-40eb-9940-114688ae5e2f",
   "metadata": {},
   "source": [
    "Zdecydowano usunąć dwie kolumny, czyli education oraz fnlwgt. Pierwsza jest zbędna, bo mamy jej numeryczny odpowiednik, a druga to waga demograficzna, która przy przewidywaniu zarobków konkretnej osoby mogłaby wprowadzić szum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c30ec6-0054-42e5-bb87-542f50203eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usuwanie kolumn\n",
    "# 'education' jest zduplikowana informacją z 'education-num'\n",
    "# 'fnlwgt' to waga demograficzna, zazwyczaj nieużyteczna w predykcji dochodu\n",
    "cols_to_drop = ['education', 'fnlwgt']\n",
    "df_X_cleaned = df_X_imputed.drop(columns=cols_to_drop)\n",
    "\n",
    "print(f\"\\nKolumny po usunięciu zbędnych: {df_X_cleaned.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26eebec-ae07-4a91-ba52-ebb51e63a04f",
   "metadata": {},
   "source": [
    "W celu poprawy jakości danych uzyto funkcję usuwającą wartości odstające metodą rozstępu międzykwartylowego dla wybranych cech numerycznych, takich jak wiek czy czas pracy. Proces ten pozwolił na oczyszczenie zbioru z szumu statystycznego, przy jednoczesnym zachowaniu zmiennych finansowych, w których skrajne wartości niosą kluczową informację dla predykcji wysokich dochodów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2020bd0d-fc32-4602-9315-17c31e38b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usuwanie Outlierów\n",
    "\n",
    "def remove_outliers_iqr(df_features, df_target, columns_to_filter, factor=1.5):\n",
    "    \n",
    "    # Tworzenie kopii\n",
    "    X_temp = df_features.copy()\n",
    "    y_temp = df_target.copy()\n",
    "    \n",
    "    # Początkowo zachowujemy wszystkie indeksy\n",
    "    valid_indices = X_temp.index\n",
    "\n",
    "    for col in columns_to_filter:\n",
    "        Q1 = X_temp[col].quantile(0.25)\n",
    "        Q3 = X_temp[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        \n",
    "        lower_bound = Q1 - (factor * IQR)\n",
    "        upper_bound = Q3 + (factor * IQR)\n",
    "        \n",
    "        # Znajdujemy indeksy wierszy, które mieszczą się w normie\n",
    "        filter_mask = (X_temp[col] >= lower_bound) & (X_temp[col] <= upper_bound)\n",
    "        valid_indices = valid_indices.intersection(X_temp[filter_mask].index)\n",
    "\n",
    "    # Zwracamy przefiltrowane dane\n",
    "    return X_temp.loc[valid_indices], y_temp.loc[valid_indices]\n",
    "\n",
    "# Wybór kolumn do czyszczenia. \n",
    "# 'capital-gain' i 'capital-loss' celowo pominięte, bo tam wysokie wartości są kluczowe dla predykcji >50K\n",
    "cols_to_check = ['age', 'hours-per-week', 'education-num']\n",
    "\n",
    "print(f\"Liczba wierszy przed usunięciem outlierów: {len(df_X_cleaned)}\")\n",
    "\n",
    "# Tworzymy nowe zmienne\n",
    "df_X_final, df_y_final = remove_outliers_iqr(df_X_cleaned, df_y, cols_to_check)\n",
    "\n",
    "print(f\"Liczba wierszy po usunięciu outlierów: {len(df_X_final)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b592689-3177-43f2-bec7-572f7e66f6fa",
   "metadata": {},
   "source": [
    "Przygotowabo dane do analizy eksploracyjnej, łącząc cechy z etykietami i zamieniając wartości binarne na czytelne nazwy kategorii, co ułatwia interpretację wyników"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca98d8a-8097-4335-b174-cbd774fa49ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ustawienia wykresów\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Łączymy X i y w jeden DataFrame tymczasowo do celów wizualizacji\n",
    "df_eda = df_X_final.copy()\n",
    "\n",
    "df_eda['income'] = df_y_final['income']  # 0 to <=50K, 1 to >50K\n",
    "\n",
    "# Zamieniamy 0/1 z powrotem na etykiety dla czytelności wykresów\n",
    "df_eda['income_label'] = df_eda['income'].map({0: '<=50K', 1: '>50K'})\n",
    "\n",
    "df_eda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc000a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wykres zmiennej celu\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.countplot(x='income_label', data=df_eda, palette='viridis', order=['<=50K', '>50K'], hue='income_label', legend=False)\n",
    "\n",
    "# Dodanie liczebności nad słupkami\n",
    "for p in ax.patches:\n",
    "    ax.annotate(f'{p.get_height()}', (p.get_x() + 0.35, p.get_height() + 100))\n",
    "\n",
    "plt.title('Rozkład zmiennej celu (Income)', fontsize=15)\n",
    "plt.xlabel('Dochód roczny')\n",
    "plt.ylabel('Liczba osób')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37834e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='income_label', y='age', data=df_eda, palette='coolwarm', order=['<=50K', '>50K'], hue='income_label', legend=False)\n",
    "plt.title('Rozkład wieku względem dochodu', fontsize=15)\n",
    "plt.xlabel('Dochód')\n",
    "plt.ylabel('Wiek')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac62ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax = sns.histplot(\n",
    "    data=df_eda,\n",
    "    x='education-num',\n",
    "    hue='income_label',\n",
    "    multiple='fill',\n",
    "    bins=16,\n",
    "    palette='magma',\n",
    "    legend=True\n",
    ")\n",
    "\n",
    "plt.title('Procentowy udział grup dochodowych w zależności od lat edukacji', fontsize=15)\n",
    "plt.xlabel('Liczba lat edukacji (education-num)')\n",
    "plt.ylabel('Udział procentowy')\n",
    "\n",
    "# Poprawne wyświetlenie legendy\n",
    "sns.move_legend(ax, \"upper right\", title=\"Income\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d354dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wybieramy tylko kolumny numeryczne do korelacji\n",
    "numeric_cols = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week', 'income']\n",
    "corr_matrix = df_eda[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Macierz korelacji zmiennych numerycznych', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf23b017-f709-415c-a53b-ad9bc6be11da",
   "metadata": {},
   "source": [
    "Ta macierz korelacji pokazuje, że najsilniejszy (choć wciąż umiarkowany) związek z dochodem ma poziom wykształcenia (0.33) oraz wiek (0.26). Pozostałe zmienne są ze sobą skorelowane bardzo słabo, co sugeruje brak silnych zależności liniowych między nimi w tym zbiorze."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cc65f2-4e44-4ad6-a62f-8cc0028e8701",
   "metadata": {},
   "source": [
    "Przeprowadzono analizę skupień przy użyciu algorytmu KMeans, skupiając się na kluczowych zmiennych takich jak wiek czy wykształcenie. Zastosowano metodę łokcia z automatycznym wyznaczaniem punktu przegięcia, co pozwoliło na optymalne pogrupowanie obserwacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f06aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Do klasteryzacji użyjemy tylko głównych zmiennych numerycznych\n",
    "cols_for_clustering = ['age', 'education-num', 'hours-per-week', 'capital-gain']\n",
    "\n",
    "# Skalowanie\n",
    "scaler_cluster = StandardScaler()\n",
    "X_cluster = scaler_cluster.fit_transform(df_eda[cols_for_clustering])\n",
    "\n",
    "# Metoda łokcia\n",
    "inertia = []\n",
    "K_range = range(1, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_cluster)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Automatyczne wykrycie łokcia\n",
    "K = np.array(list(K_range))\n",
    "inertia_arr = np.array(inertia)\n",
    "\n",
    "# Linia łącząca pierwszy i ostatni punkt\n",
    "p1 = np.array([K[0], inertia_arr[0]])\n",
    "p2 = np.array([K[-1], inertia_arr[-1]])\n",
    "\n",
    "# Odległość punktów od tej linii\n",
    "distances = []\n",
    "for i in range(len(K)):\n",
    "    p = np.array([K[i], inertia_arr[i]])\n",
    "    distance = np.abs(np.cross(p2 - p1, p1 - p)) / np.linalg.norm(p2 - p1)\n",
    "    distances.append(distance)\n",
    "\n",
    "elbow_k = K[np.argmax(distances)]\n",
    "elbow_inertia = inertia_arr[np.argmax(distances)]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K, inertia_arr, marker='o', linestyle='--', label='Inertia')\n",
    "plt.scatter(elbow_k, elbow_inertia, color='red', s=120, label=f'Łokieć: k={elbow_k}')\n",
    "plt.axvline(x=elbow_k, color='red', linestyle=':', alpha=0.7)\n",
    "\n",
    "plt.title('Metoda łokcia – automatyczny wybór liczby klastrów')\n",
    "plt.xlabel('Liczba klastrów (k)')\n",
    "plt.ylabel('Suma kwadratów odległości wewnątrz klastra (Inertia)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5e4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ustawiamy liczbę klastrów\n",
    "optimal_k = 5\n",
    "\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "df_eda['cluster'] = kmeans.fit_predict(X_cluster)\n",
    "\n",
    "# Średnie wartości cech w każdym klastrze\n",
    "cluster_summary = df_eda.groupby('cluster')[cols_for_clustering + ['income']].mean()\n",
    "cluster_counts = df_eda['cluster'].value_counts().sort_index()\n",
    "\n",
    "print(\"--- Charakterystyka klastrów (średnie wartości) ---\")\n",
    "print(cluster_summary)\n",
    "print(\"\\n--- Liczebność klastrów ---\")\n",
    "print(cluster_counts)\n",
    "\n",
    "# Wizualizacja klastrów\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='age', y='hours-per-week', hue='cluster', data=df_eda, palette='bright', alpha=0.6)\n",
    "plt.title('Segmentacja: Wiek vs Godziny pracy (kolory to klastry)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40fcfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "scatter = ax.scatter(\n",
    "    df_eda['age'],\n",
    "    df_eda['hours-per-week'],\n",
    "    df_eda['capital-gain'],\n",
    "    c=df_eda['cluster'],\n",
    "    cmap='tab10',\n",
    "    alpha=0.6\n",
    ")\n",
    "\n",
    "ax.set_xlabel('Age')\n",
    "ax.set_ylabel('Hours per week')\n",
    "ax.set_zlabel('Capital gain')\n",
    "ax.set_title('Klastry w przestrzeni 3D')\n",
    "\n",
    "legend = ax.legend(*scatter.legend_elements(), title=\"Cluster\")\n",
    "ax.add_artist(legend)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c03d0c",
   "metadata": {},
   "source": [
    "### 3. Graficzna i opisowa analiza eksploracyjna (EDA)\n",
    "\n",
    "#### 3.1. Analiza zmiennej celu i korelacji\n",
    "* **Niezbalansowanie klas:**\n",
    "    * Po oczyszczeniu danych z wartości odstających (outlierów), proporcje klas pozostają zbliżone do pierwotnych: większość stanowią osoby o dochodzie **<=50K**, co narzuca konieczność stosowania metryki F1-score podczas oceny modeli.\n",
    "* **Kluczowe korelacje:**\n",
    "    1.  **Education-num:** Nadal pozostaje silnym predyktorem – wyższy poziom edukacji wyraźnie zwiększa szansę na wysokie zarobki.\n",
    "    2.  **Age:** Zarobki rosną wraz z doświadczeniem, choć po osiągnięciu wieku emerytalnego (widoczne w klastrach starszych) tendencja ta może wyhamowywać.\n",
    "    3.  **Hours-per-week:** Istotna korelacja dodatnia, co potwierdziła analiza klastrów (szczególnie w grupie o średnim wykształceniu).\n",
    "\n",
    "#### 3.2. Wyniki segmentacji (Algorytm K-Means)\n",
    "Na podstawie przetworzonych danych wyłoniono **5 charakterystycznych klastrów**, które ujawniają różne ścieżki do osiągnięcia wyższych dochodów:\n",
    "\n",
    "* **Klaster 0: \"Start kariery / Niskie kwalifikacje\" (~36% populacji)**\n",
    "    * **Liczebność:** 12 285 osób (najliczniejsza grupa).\n",
    "    * **Profil:** Najmłodsza grupa (śr. 29 lat) ze średnim wykształceniem (~9 lat) i standardowym czasem pracy.\n",
    "    * **Dochód:** Tylko **8.9%** zarabia >50K. Jest to grupa bazowa, dopiero wchodząca na rynek pracy lub wykonująca proste zawody.\n",
    "\n",
    "* **Klaster 4: \"Starsi z niższym wykształceniem\" (~23.5% populacji)**\n",
    "    * **Liczebność:** 7 990 osób.\n",
    "    * **Profil:** Najstarsza grupa (śr. 52 lata), ale o poziomie edukacji zbliżonym do grupy najmłodszej (~9 lat).\n",
    "    * **Dochód:** **25.5%** zarabia >50K.\n",
    "    * *Wniosek:* Wiek i doświadczenie rekompensują braki w edukacji tylko w umiarkowanym stopniu.\n",
    "\n",
    "* **Klaster 3: \"Wykształceni profesjonaliści\" (~22.5% populacji)**\n",
    "    * **Liczebność:** 7 671 osób.\n",
    "    * **Profil:** Osoby w średnim wieku (~39 lat) z **najwyższym poziomem edukacji** (śr. 13.2 lat, co odpowiada studiom wyższym) pracujące standardowe 40h/tydzień.\n",
    "    * **Dochód:** **41.4%** zarabia >50K.\n",
    "    * *Wniosek:* Wysokie kwalifikacje pozwalają na wysokie zarobki bez konieczności pracy w nadgodzinach.\n",
    "\n",
    "* **Klaster 2: \"Pracowici średniego szczebla\" (~17% populacji)**\n",
    "    * **Liczebność:** 5 912 osób.\n",
    "    * **Profil:** Podobny wiek co w Klastrze 3 (~39 lat) i średnie wykształcenie (~11 lat), ale wyróżniający się **bardzo wysokim nakładem pracy** (śr. 49h/tydz.).\n",
    "    * **Dochód:** **41.1%** zarabia >50K.\n",
    "    * *Wniosek:* Osoby z niższym wykształceniem niż profesjonaliści \"nadrabiają\" zarobki, pracując znacznie ciężej (nadgodziny).\n",
    "\n",
    "* **Klaster 1: \"Zamożni inwestorzy\" (<0.5% populacji)**\n",
    "    * **Liczebność:** 142 osoby (grupa elitarna).\n",
    "    * **Profil:** Grupa specyficzna, zdefiniowana przez maksymalny zysk kapitałowy (**$99,999**).\n",
    "    * **Dochód:** **100%** osób w tej grupie zarabia >50K. Są to outliery pod względem finansowym, które celowo pozostawiono w zbiorze danych ze względu na ich istotność predykcyjną."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7289613c-4b20-479b-b6ba-4a35c981120a",
   "metadata": {},
   "source": [
    "Następnie, uzyto One-Hot Encoding. Dodatkowo użyto StandardScaler dla zmiennych liczbowych, żeby takie wartości jak wiek czy godziny pracy miały podobną skalę i nie dominowały nad resztą cech podczas uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7b72f-d588-4992-871e-c893f89a4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding dla zmiennych kategorycznych\n",
    "categorical_cols = df_X_final.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Używamy get_dummies (pandas) dla szybkiego kodowania\n",
    "df_X_encoded = pd.get_dummies(df_X_final, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "# Podział na zbiór treningowy i testowy\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df_X_encoded, \n",
    "    df_y_final['income'], \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=df_y_final['income']\n",
    ")\n",
    "\n",
    "# Standaryzacja zmiennych numerycznych\n",
    "# Skalujemy tylko na podstawie zbioru treningowego, żeby nie było wycieku danych\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Lista kolumn numerycznych, które zostały w danych\n",
    "num_cols_to_scale = ['age', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "\n",
    "X_train[num_cols_to_scale] = scaler.fit_transform(X_train[num_cols_to_scale])\n",
    "X_test[num_cols_to_scale] = scaler.transform(X_test[num_cols_to_scale])\n",
    "\n",
    "print(\"Gotowe wymiary danych treningowych:\", X_train.shape)\n",
    "print(\"Przykładowe 5 wierszy danych po przetworzeniu:\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c38c5eb-193b-4738-938b-c9a101ea5fa2",
   "metadata": {},
   "source": [
    "**Regresja logistyczna:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489247cf-1c73-40f4-8737-0113ff743248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, \n",
    "                             roc_curve, auc, precision_recall_curve, \n",
    "                             accuracy_score, f1_score)\n",
    "\n",
    "# Model bazowy\n",
    "lr_model = LogisticRegression(solver='liblinear', max_iter=1000, random_state=42)\n",
    "\n",
    "# Siatka hiperparametrów\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Tuning przy użyciu GridSearchCV (8-krotna walidacja krzyżowa, metryka f1)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=lr_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=8,\n",
    "    scoring='f1',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_lr = grid_search.best_estimator_\n",
    "print(f\"Najlepsze parametry: {grid_search.best_params_}\")\n",
    "print(f\"Najlepszy wynik F1: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=['<=50K', '>50K'], \n",
    "                yticklabels=['<=50K', '>50K'])\n",
    "    plt.title('Macierz Konfuzji')\n",
    "    plt.ylabel('Rzeczywistość')\n",
    "    plt.xlabel('Predykcja')\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'Krzywa ROC (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Krzywa ROC')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.savefig('roc_curve.png')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Wywołanie ewaluacji (po wytrenowaniu)\n",
    "evaluate_model(best_lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a3c4c7-3e9e-478a-b1d3-6ff382706840",
   "metadata": {},
   "source": [
    "**Optymalne parametry:** Najlepsze wyniki (F1-score $\\approx$ 0,66) model osiągnął przy silnej regularyzacji L1 (C=100), co sugeruje, że tylko część cech ma kluczowy wpływ na wynik.\n",
    "\n",
    "**Problem czułości (Recall):** Model poprawnie identyfikuje 93% osób zarabiających $\\le 50K$, ale ma trudności z wykrywaniem klasy mniejszościowej – tylko 60% osób z wysokim dochodem zostało poprawnie sklasyfikowanych.\n",
    "\n",
    "**Ogólna skuteczność:** Wysoka dokładność (Accuracy = 84%) jest nieco myląca ze względu na niezbalansowanie klas; model jest \"ostrożny\" w przypisywaniu wysokich zarobków, co potwierdza przewaga precyzji (0,76) nad czułością (0,60) dla klasy 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a2f5e4-ce44-45fa-9ab6-39aed431336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns\n",
    "coefficients = best_lr.coef_[0]\n",
    "\n",
    "feat_importances = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "feat_importances['AbsCoefficient'] = feat_importances['Coefficient'].abs()\n",
    "feat_importances = feat_importances.sort_values(by='Coefficient', ascending=False)\n",
    "\n",
    "# Wizualizacja 10 najsilniejszych pozytywnych i 10 najsilniejszych negatywnych wpływów\n",
    "top_bottom_features = pd.concat([feat_importances.head(10), feat_importances.tail(10)])\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='Coefficient', y='Feature', data=top_bottom_features)\n",
    "plt.title('Najważniejsze cechy w modelu Regresji Logistycznej', fontsize=15)\n",
    "plt.xlabel('Wartość współczynnika (Wpływ na prawdopodobieństwo >50K)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce07d07b-fdcb-423f-b966-5257affb0d90",
   "metadata": {},
   "source": [
    "**GradientBoosting:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9939e0-74f6-4f61-be5c-8ba5fd6b3f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],        # Liczba drzew\n",
    "    'learning_rate': [0.05, 0.1, 0.2], # Jak szybko model się uczy\n",
    "    'max_depth': [3, 4, 5],            # Głębokość pojedynczego drzewa\n",
    "    'subsample': [0.8, 1.0]            # Użycie części danych do każdego drzewa\n",
    "}\n",
    "\n",
    "# Konfiguracja przeszukiwania siatki (Grid Search) z walidacją krzyżową (CV)\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,                 # 3-krotna walidacja krzyżowa\n",
    "    scoring='f1',         # Optymalizacja pod kątem F1-score (dla klasy 1)\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Trenowanie modelu\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Wyniki tuningu\n",
    "best_gb_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"\\n--- WYNIKI TUNINGU ---\")\n",
    "print(f\"Najlepsze parametry: {grid_search.best_params_}\")\n",
    "print(f\"Najlepszy wynik F1-Score (cross-validation): {grid_search.best_score_:.4f}\")\n",
    "\n",
    "# Predykcja na zbiorze testowym\n",
    "y_pred = best_gb_model.predict(X_test)\n",
    "\n",
    "# Wyświetlenie raportu klasyfikacji\n",
    "print(\"\\n--- RAPORT KLASYFIKACJI (ZBIÓR TESTOWY) ---\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Wyświetlenie Macierzy Pomyłek\n",
    "print(\"--- MACIERZ POMYŁEK ---\")\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1386f2a-0bb2-4f29-b1be-d338f105882c",
   "metadata": {},
   "source": [
    "F1-Score = 0.7076. Gradient Boosting okazał się bardziej skuteczny od regresji logistycznej\n",
    "\n",
    "Accuracy = 87%: Model ogólnie myli się rzadko.\n",
    "\n",
    "Recall dla klasy 1 (0.66).\n",
    "Model rzadziej pomija osoby zamożne przy zachowaniu wysokiej precyzji (0,79)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b084c4-908e-4b02-8b3f-2629f187f345",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(\n",
    "    best_gb_model, \n",
    "    X_test, \n",
    "    y_test, \n",
    "    display_labels=['<=50K', '>50K'],\n",
    "    cmap='Blues',\n",
    "    normalize=None,\n",
    "    ax=ax \n",
    ")\n",
    "\n",
    "ax.set_title(\"Macierz Pomyłek (Liczebność)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f017a86-e1d4-4d17-aa1e-1d4bee8818d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "RocCurveDisplay.from_estimator(\n",
    "    best_gb_model, \n",
    "    X_test, \n",
    "    y_test, \n",
    "    name=\"Gradient Boosting\",\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "ax.plot([0, 1], [0, 1], \"k--\", label=\"AUC = 0.5\")\n",
    "ax.set_title(\"Krzywa ROC\")\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580165ff-0574-4f91-b3da-e6afea38c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "importances = best_gb_model.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "feat_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "feat_importances.nlargest(10).plot(kind='barh', ax=ax, color='teal', edgecolor='black')\n",
    "\n",
    "ax.set_title(\"TOP 10 Cech decydujących o dochodzie\")\n",
    "ax.set_xlabel(\"Waga cechy (Importance)\")\n",
    "ax.invert_yaxis()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5653df4d-10a6-487a-aabc-8fe0b18d12d0",
   "metadata": {},
   "source": [
    "**Random Forest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864c837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definicja modelu\n",
    "rf = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Siatka parametrów do przetestowania\n",
    "# Sprawdzamy liczbę drzew, głębokość oraz wagę klas\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],       # Liczba drzew\n",
    "    'max_depth': [10, 20, None],      # Maksymalna głębokość\n",
    "    'min_samples_leaf': [1, 4],       # Minimalna liczba próbek w liściu\n",
    "    'class_weight': ['balanced', None] # Czy wyrównywać wagi dla mniejszej klasy (>50K)\n",
    "}\n",
    "\n",
    "# Konfiguracja przeszukiwania (optymalizacja pod kątem F1-score)\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid_rf,\n",
    "    cv=8,             # 8-krotna walidacja krzyżowa\n",
    "    scoring='f1',     # Skupiamy się na F1 \n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "print(f\"\\nNajlepsze parametry: {grid_search_rf.best_params_}\")\n",
    "print(f\"Najlepszy wynik F1 (CV): {grid_search_rf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0125b598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Raport tekstowy\n",
    "print(classification_report(y_test, y_pred_rf, target_names=['<=50K', '>50K']))\n",
    "\n",
    "# Ustawienie obszaru wykresów\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Macierz Pomyłek (Znormalizowana)\n",
    "ConfusionMatrixDisplay.from_estimator(best_rf, X_test, y_test, \n",
    "                                      display_labels=['<=50K', '>50K'], \n",
    "                                      cmap='Greens', normalize='true', ax=axes[0])\n",
    "axes[0].set_title('Znormalizowana Macierz Pomyłek')\n",
    "\n",
    "# Krzywa ROC\n",
    "RocCurveDisplay.from_estimator(best_rf, X_test, y_test, ax=axes[1], name='Random Forest')\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', label='Losowy wybór')\n",
    "axes[1].set_title('Krzywa ROC')\n",
    "\n",
    "# Ważność cech (Feature Importance)h\n",
    "importances = best_rf.feature_importances_\n",
    "# Pobranie nazw kolumn\n",
    "feature_names = X_train.columns if hasattr(X_train, 'columns') else [f\"Feature {i}\" for i in range(X_train.shape[1])]\n",
    "feat_importances = pd.Series(importances, index=feature_names).sort_values(ascending=False).head(10)\n",
    "\n",
    "sns.barplot(x=feat_importances.values, y=feat_importances.index, palette='viridis', ax=axes[2], hue=feat_importances.index, legend=False)\n",
    "axes[2].set_title('TOP 10 Najważniejszych Cech')\n",
    "axes[2].set_xlabel('Waga cechy (Gini Importance)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96932c07",
   "metadata": {},
   "source": [
    "* **Wysoka Czułość (Recall) dla klasy >50K: 80%**\n",
    "    * Model skutecznie \"wyłapuje\" osoby zamożne.\n",
    "    * Bardzo niskie ryzyko przeoczenia klienta docelowego.\n",
    "\n",
    "* **Precyzja (Precision) dla klasy >50K: 62%**\n",
    "    * Koszt wysokiej czułości: spora liczba False Positives.\n",
    "    * Model jest nadgorliwy – czasem klasyfikuje klasę średnią jako bogatą.\n",
    "\n",
    "* **Accuracy: 82%**\n",
    "    * Wynik niższy od modeli prostych, ale moze byc bardziej wartościowy biznesowo (model nie ignoruje mniejszości).\n",
    "\n",
    "**Wniosek:**\n",
    "Model przyjmuje strategię agresywną. Jest dobry, gdy koszt pominięcia zamoznego \n",
    "klienta jest wyższy niż koszt pomyłki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2b4e8-7aa8-4ce5-bf67-e857a27c47f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": (best_lr, X_test),\n",
    "    \"Gradient Boosting\": (best_gb_model, X_test),\n",
    "    \"Random Forest\": (best_rf, X_test)\n",
    "}\n",
    "\n",
    "# 2. Wspólny wykres krzywych ROC\n",
    "plt.figure(figsize=(10, 8))\n",
    "for name, (model, data_test) in models.items():\n",
    "    probs = model.predict_proba(data_test)[:, 1]\n",
    "    fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Losowy wybór')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Porównanie krzywych ROC')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 3. Porównanie macierzy\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for i, (name, (model, data_test)) in enumerate(models.items()):\n",
    "    y_pred = model.predict(data_test)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i], cbar=False)\n",
    "    axes[i].set_title(f'Macierz: {name}')\n",
    "    axes[i].set_xticklabels(['<=50K', '>50K'])\n",
    "    axes[i].set_yticklabels(['<=50K', '>50K'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Wybór najlepszego modelu\n",
    "comparison_data = []\n",
    "for name, (model, data_test) in models.items():\n",
    "    y_pred = model.predict(data_test)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    comparison_data.append({\"Model\": name, \"F1-Score\": f1, \"Accuracy\": acc})\n",
    "\n",
    "df_comp = pd.DataFrame(comparison_data).sort_values(by=\"F1-Score\", ascending=False)\n",
    "print(\"\\nRANKING MODELI (wg F1-Score):\")\n",
    "print(df_comp.to_string(index=False))\n",
    "\n",
    "best_model_name = df_comp.iloc[0]['Model']\n",
    "print(f\"\\nNAJLEPSZY MODEL: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd01d12-9aa8-4b5f-848a-2407e459e710",
   "metadata": {},
   "source": [
    "W ostatnim etapie prac zestawiono wszystkie wytrenowane modele, aby bezpośrednio porównać ich skuteczność na zbiorze testowym przy użyciu wspólnej charakterystyki ROC oraz macierzy pomyłek. Wygenerowanie zbiorczego rankingu pozwala na ocenę, który algorytm najlepiej radzi sobie z wyważeniem precyzji i czułości w problemie klasyfikacji dochodów. Dzięki wizualizacji krzywych ROC mogliśmy sprawdzić ogólną zdolność modeli do odseparowania obu klas niezależnie od przyjętego progu prawdopodobieństwa.\n",
    "\n",
    "**Zwycięzca zestawienia:** Najlepsze wyniki osiągnął model **Gradient Boosting**, który uzyskał najwyższy wskaźnik F1-Score **(0,719)** oraz najwyższą ogólną dokładność (86,6%), co czyni go najbardziej zbalansowanym klasyfikatorem.\n",
    "\n",
    "**Charakterystyka Random Forest:** Model ten zajął drugie miejsce w rankingu; mimo bardzo wysokiej zdolności do wykrywania osób zamożnych (wysoki recall), generował on więcej błędów typu False Positive niż Gradient Boosting.\n",
    "\n",
    "Wszystkie modele uzyskały **wysokie i zbliżone wartości AUC**, co potwierdza poprawność przeprowadzonego procesu inżynierii cech i przygotowania danych."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
